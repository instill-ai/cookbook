{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/instill-ai/cookbook/main/images/Logo.png\" alt=\"Instill Logo\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Your PDF Files AI-Ready\n",
    "\n",
    "In this notebook, we will leverage **Instill VDP** pipelines hosted on the **Instill Cloud** platform to transform PDF files into high-quality Markdown formatted text, suitable for AI applications.\n",
    "\n",
    "### Why Does This Matter?\n",
    "\n",
    "If you are building an AI or ML system, the level of performance you can achieve is almost entirely determined by the quality of the data you use to build or train that system: **Garbage In** $=$ **Garbage Out**. Oftentimes, you may want to build AI systems, such as RAG assistants or fine-tuned LLMs, using the information contained in documents such as PDF files. Despite their abundance throughout almost all organizations, PDF files are notoriously difficult to parse accurately due to the diversity of layouts, embedded images, charts, and non-standard fonts.\n",
    "\n",
    "### Why Markdown?\n",
    "\n",
    "Markdown is an ideal format for AI applications because it offers a balance between simplicity and structure. It provides a lightweight, human-readable way to represent documents while preserving essential formatting elements like headings, lists, and links. Unlike raw text, Markdown captures the document's hierarchy and formatting in a clear, organized manner, making it easier for AI models to extract meaning and context. This structured format maximizes its utility for AI processing, enabling better performance in tasks like text summarization, document classification, and question answering.\n",
    "\n",
    "### Flexibility Based on Document Complexity\n",
    "\n",
    "There’s no one-size-fits-all solution for parsing PDF documents into Markdown because every document is different. Some may have simple text and formatting, while others include intricate tables, images, or specialized formatting like mathematical equations. A PDF could even be a scanned hand-written note. Depending on the complexity of the document, we provide multiple approaches, allowing you to choose the best method for your particular use case:\n",
    "\n",
    "1. **Transform any document** (PDF/DOCX/DOC/PPTX/PPT/HTML/XLSX) into Markdown using the **Instill Component** [Document Operator](https://www.instill.tech/docs/component/operator/document#convert-to-markdown).\n",
    "2. **PDF-to-Markdown conversion with LLM correction** using a [pipeline](https://instill.tech/george_strong/pipelines/llm-corrected-pdf-to-markdown/playground) that leverages a Large Language Model (LLM) to supervise and improve the formatting of Markdown output generated by the Document Operator.\n",
    "3. **PDF-to-Markdown conversion with VLM correction** using a [pipeline](https://instill.tech/george_strong/pipelines/vlm-corrected-pdf-to-markdown/playground) that first converts pages to images, and then leverages a Visual Language Model (VLM) to supervise and improve the formatting of the Document Operator output using the images as context.\n",
    "\n",
    "In this notebook, we will demonstrate how to use each of these methods via our Python SDK. The PDF document we will be demonstrating on is the famous [AlexNet paper](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "To execute all of the code in this notebook, you’ll need to create a free Instill Cloud account and setup an API Token. To create your account, please refer to our [quickstart guide](https://www.instill.tech/docs/quickstart). For generating your API Token, consult the [API Token Management](https://www.instill.tech/docs/core/token) page.\n",
    "\n",
    "**This will give you access to 10,000 free credits per month that you can use to make API calls with third-party AI vendors. Please see our [documentation](https://www.instill.tech/docs/cloud/credit) for further details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now install the latest Instill Python SDK, import the required libraries, and configure the SDK with a valid API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install instill-sdk==0.11.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from instill.clients.client import init_pipeline_client\n",
    "#pipeline = init_pipeline_client(api_token=\"YOUR_INSTILL_API_TOKEN\")\n",
    "\n",
    "import os\n",
    "pipeline = init_pipeline_client(api_token=os.getenv(\"INSTILL_API_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download and base64 encode the [AlexNet PDF](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) file we will be converting to Markdown-formatted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet_paper = \"https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\"\n",
    "\n",
    "alexnet_response = requests.get(alexnet_paper)\n",
    "alexnet_base64 = base64.b64encode(alexnet_response.content).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instill Component Document Operator\n",
    "\n",
    "First, we will transform the PDF file into Markdown using the **Instill Component** [Document Operator](https://www.instill.tech/docs/component/operator/document). This is the fastest, cheapest, and lowest latency option available. To implement this, we will be using the [standard-doc-to-markdown](https://instill.tech/george_strong/pipelines/standard-doc-to-markdown/playground) pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline.trigger_namespace_pipeline(\n",
    "    \"george_strong\",\n",
    "    \"standard-doc-to-markdown\",\n",
    "    [{\"file\": alexnet_base64}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md(response):\n",
    "    return response.outputs[0].fields['markdown'].string_value\n",
    "\n",
    "\n",
    "md_text = get_md(response)\n",
    "print(md_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the Markdown-formatted text output, the [Document Operator](https://www.instill.tech/docs/component/operator/document#convert-to-markdown) also outputs images that have been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(response):\n",
    "    return response.outputs[0].fields['images'].list_value.values\n",
    "\n",
    "\n",
    "images = get_images(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(base64_strings, images_per_row=4):\n",
    "    num_images = len(base64_strings)\n",
    "    num_rows = math.ceil(num_images / images_per_row)\n",
    "\n",
    "    plt.figure(figsize=(images_per_row * 2, num_rows * 2))\n",
    "\n",
    "    for i, b64_str in enumerate(base64_strings):\n",
    "        base64_data = b64_str.string_value.split(',')[1]\n",
    "\n",
    "        image_data = base64.b64decode(base64_data)\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        plt.subplot(num_rows, images_per_row, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_images(images, images_per_row=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PDF-to-Markdown conversion with LLM correction\n",
    "\n",
    "We will now use the [Document Operator](https://www.instill.tech/docs/component/operator/document#convert-to-markdown) in tandem with a LLM whose task is to supervise and improve the formatting of Markdown output previously generated by the Document Operator. Checkout the pipeline Preview and README pages below for additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('https://instill.tech/george_strong/pipelines/llm-corrected-pdf-to-markdown/preview', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline.trigger_namespace_pipeline(\n",
    "    \"george_strong\",\n",
    "    \"llm-corrected-pdf-to-markdown\",\n",
    "    [{\"file\": alexnet_base64}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = get_md(response)\n",
    "print(md_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PDF-to-Markdown conversion with VLM correction\n",
    "\n",
    "In this approach, we use the [Document Operator](https://www.instill.tech/docs/component/operator/document) to convert the PDF file to Markdown-formatted text, alongside another document component that transforms each page into a separate image. A VLM is then instructed to supervise and improve the formatting of Markdown output previously generated by the Document Operator using the images as context.\n",
    "\n",
    "For optimal performance, it is recommended that you only parse a couple of pages at a time when using this method. If this limit is exceeded, the VLM may struggle to adhere to all of the context provided in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame('https://instill.tech/george_strong/pipelines/vlm-corrected-pdf-to-markdown/preview', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To break up the PDF into separate pages, we will use [PyMuPDF](https://pymupdf.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alexnet_paper.pdf\", 'wb') as f:\n",
    "    f.write(alexnet_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_document = pymupdf.open(\"alexnet_paper.pdf\")\n",
    "num_pages = len(pdf_document)\n",
    "num_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize performance, let's run each page separately through the pipeline by setting `group_size` to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = 1\n",
    "encoded_groups = []\n",
    "\n",
    "for i in range(0, num_pages, group_size):\n",
    "    end_page = min(i + group_size, num_pages)\n",
    "\n",
    "    pdf_writer = pymupdf.open()\n",
    "    for page_num in range(i, end_page):\n",
    "        pdf_writer.insert_pdf(pdf_document, from_page=page_num, to_page=page_num)\n",
    "    \n",
    "    pdf_bytes = io.BytesIO()\n",
    "    pdf_writer.save(pdf_bytes)\n",
    "    pdf_writer.close()\n",
    "    \n",
    "    encoded_pdf = base64.b64encode(pdf_bytes.getvalue()).decode('utf-8')\n",
    "    encoded_groups.append(encoded_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse each page to Markdown in parallel using `ThreadPoolExecutor()` from Python's `concurrent.futures` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_group(encoded_group):\n",
    "    return pipeline.trigger_namespace_pipeline(\n",
    "        \"george_strong\",\n",
    "        \"vlm-corrected-pdf-to-markdown\",\n",
    "        [{\"file\": encoded_group}]\n",
    "    )\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    responses = list(executor.map(process_group, encoded_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge each page back together to form a single Markdown-formatted text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = \"\"\n",
    "\n",
    "for response in responses:\n",
    "    markdown_content = response.outputs[0].fields['markdown'].string_value\n",
    "    md_text += markdown_content + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(md_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
