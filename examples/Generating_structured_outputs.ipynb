{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/instill-ai/cookbook/main/images/Logo.png\" alt=\"Instill Logo\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Structured Output from LLMs\n",
    "\n",
    "OpenAI recently announced that they now support [**Structured Outputs in the API**](https://openai.com/index/introducing-structured-outputs-in-the-api/) with general availability. The ability to distill and transform the creative and diverse unstructured outputs of Large Language Models (LLMs) into an actionable and reliable structured data represents a huge milestone in the world of Unstructured Data ETL. However, there's more to the story than meets the eye!\n",
    "\n",
    "Coincidently, and perhaps ironically, a paper was published the day before this OpenAI announcement, titled [**Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models**](https://arxiv.org/abs/2408.02442v1). It shines a revealing light on the limitations of forcing structured outputs from LLMs. In particular, they found that LLMs tend to **struggle with reasoning tasks when they're placed under format restrictions**. Additionally, the _stricter_ these format restrictions are, the _more_ their reasoning performance drops.\n",
    "\n",
    "### Contents\n",
    "\n",
    "In this notebook, we will explore this very problem by implementing and benchmarking the current state-of-the-art tools for generating structured outputs from LLMs. The tools and libraries that we will consider are:\n",
    "\n",
    "1. [**Instructor**](https://python.useinstructor.com) - a Python library, built on top of Pydantic, that lets you generate structured output from LLMs\n",
    "2. [**Marvin**](https://www.askmarvin.ai) - a Python library for building reliable natural language interfaces\n",
    "3. [**BAML**](https://www.boundaryml.com) - a domain specific language to write and test LLM functions\n",
    "4. [**TypeChat**](https://microsoft.github.io/TypeChat/) - a tool from Microsoft for getting well-typed responses from language models\n",
    "\n",
    "[Outlines](https://outlines-dev.github.io/outlines/), [JSONformer](https://github.com/1rgs/jsonformer) and [Guidance](https://github.com/guidance-ai/guidance/tree/main) were also considered, however they were left out of this experiment as they had limited support for remote API calls and failed when integrating with the OpenAI API.\n",
    "\n",
    "We will then evaluate this problem with the latest OpenAI [Structured Outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/) feature using Versatile Data Pipelines - **üíß Instill VDP** - hosted on **‚òÅÔ∏è Instill Cloud**.\n",
    "\n",
    "### Benchmark Task\n",
    "\n",
    "The task we will use to test, compare and evaluate the performance of these methods is directly inspired from Figure 1 of the aforementioned [paper](https://arxiv.org/abs/2408.02442v1):\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/instill-ai/cookbook/main/images/Speak_freely.png\" alt=\"Figure 1\" width=\"390\"/>\n",
    "\n",
    "In our task, we ramp up the complexity by combining an analogous reasoning problem to the one shown above with text summarization. More precisely, we ask the LLM/output structuring tool to summarize the contents of a resume into the following structure:\n",
    "```Python\n",
    "name: str\n",
    "email: str\n",
    "cost: float\n",
    "reasoning: str\n",
    "experience: list[str]\n",
    "skills: list[str]\n",
    "```\n",
    "where `cost` represents the answer to the question:\n",
    "> John Doe is a freelance software engineer. He charges a \n",
    "        base rate of $50 per hour for the first 29 hours of work \n",
    "        each week. For any additional hours, he charges 1.7 \n",
    "        times his base hourly rate. This week, John worked on a \n",
    "        project for 38 hours. How much will John Doe charge his \n",
    "        client for the project this week?\n",
    "\n",
    "and `reasoning` contains the rationale and steps behind the calculated cost. See below for the example resume we will use, as well as the correct `cost` response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = \"\"\"\n",
    "    John Doe\n",
    "    1234 Elm Street \n",
    "    Springfield, IL 62701\n",
    "    (123) 456-7890\n",
    "    Email: john.doe@gmail.com\n",
    "\n",
    "    Objective: To obtain a position as a software engineer.\n",
    "\n",
    "    Education:\n",
    "    Bachelor of Science in Computer Science\n",
    "    University of Illinois at Urbana-Champaign\n",
    "    May 2020 - May 2024\n",
    "\n",
    "    Experience:\n",
    "    Software Engineer Intern\n",
    "    Google\n",
    "    May 2022 - August 2022\n",
    "    - Worked on the Google Search team\n",
    "    - Developed new features for the search engine\n",
    "    - Wrote code in Python and C++\n",
    "\n",
    "    Software Engineer Intern\n",
    "    Facebook\n",
    "    May 2021 - August 2021\n",
    "    - Worked on the Facebook Messenger team\n",
    "    - Developed new features for the messenger app\n",
    "    - Wrote code in Python and Java\n",
    "    \"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "    Question:\n",
    "    John Doe is a freelance software engineer. He charges a \n",
    "    base rate of $50 per hour for the first 29 hours of work \n",
    "    each week. For any additional hours, he charges 1.7 \n",
    "    times his base hourly rate. This week, John worked on a \n",
    "    project for 38 hours. How much will John Doe charge his \n",
    "    client for the project this week?\n",
    "    \"\"\"\n",
    "\n",
    "context = resume + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Answer: $2215.0\n"
     ]
    }
   ],
   "source": [
    "true_answer = (50*29) + (1.7*50*9)\n",
    "print(f'Correct Answer: ${true_answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "To execute all of the code in this notebook, you‚Äôll need to create a free **‚òÅÔ∏è Instill Cloud** account and setup an API Token. To create your account, please refer to our [quickstart guide](https://www.instill.tech/docs/quickstart). For generating your API Token, consult the [API Token Management](https://www.instill.tech/docs/core/token) page.\n",
    "\n",
    "**This will give you access to 10,000 free credits per month that you can use to make API calls with third-party AI vendors. Please see our [documentation](https://www.instill.tech/docs/cloud/credit) for further details.**\n",
    "\n",
    "Whilst you can run all **üíß Instill VDP** pipelines using your 10,000 free monthly credits, please note that you will need a valid OpenAI API key to run the structured LLM output evaluations (e.g. for Instructor, Marvin, BAML, TypeChat). Once you have created one via the OpenAI website, please set it as an environment variable by running the following line, but replacing `*********` for your OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY='**********'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now install the latest Instill Python SDK, import the required libraries, and configure the SDK with a valid API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install instill-sdk --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instill.clients import InstillClient\n",
    "from instill.configuration import global_config\n",
    "from google.protobuf.struct_pb2 import Struct\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from IPython.display import IFrame\n",
    "import os\n",
    "\n",
    "global_config.set_default(\n",
    "    url=\"api.instill.tech\",\n",
    "    token=\"YOUR_INSTILL_API_TOKEN\", # <-- Insert your Instill API token here\n",
    "    secure=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. OpenAI Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add OpenAI Baseline test with VDP on Instill Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instructor\n",
    "\n",
    "[Instructor](https://python.useinstructor.com) is a Python library, built on top of Pydantic, that lets you generate structured output from LLMs. Here is how you can easily get started with it, and test its performance on the benchmark task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U instructor --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class DataModel(BaseModel):\n",
    "    name: str\n",
    "    email: str\n",
    "    cost: float\n",
    "    reasoning: str\n",
    "    experience: list[str]\n",
    "    skills: list[str]\n",
    "\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "    Extract from this content:\n",
    "    {resume}\n",
    "    Answer the question, storing the result in cost, and the step-by-step reasoning in reasoning.\n",
    "    \"\"\"\n",
    "\n",
    "prompt = template.format(resume=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 16:29:13,269.269 INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'email': 'john.doe@gmail.com',\n",
       " 'cost': 1985.0,\n",
       " 'reasoning': 'John charges $50 per hour for the first 29 hours. This amounts to $50 * 29 = $1450. For the remaining 9 hours (38-29), he charges 1.7 times his base rate, which is $50 * 1.7 = $85 per hour. This amounts to $85 * 9 = $765. Therefore, the total cost for this week would be $1450 + $765 = $1985.',\n",
       " 'experience': ['Software Engineer Intern at Google from May 2022 to August 2022. Worked on the Google Search team, developed new features for the search engine, wrote code in Python and C++.',\n",
       "  'Software Engineer Intern at Facebook from May 2021 to August 2021. Worked on the Facebook Messenger team, developed new features for the messenger app, wrote code in Python and Java.'],\n",
       " 'skills': ['Python', 'Java', 'C++']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructor_response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    response_model=DataModel,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "\n",
    "instructor_dict = instructor_response.model_dump()\n",
    "instructor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructor error: $230.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Instructor error: ${abs(instructor_dict[\"cost\"]-true_answer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Marvin\n",
    "\n",
    "[Marvin](https://www.askmarvin.ai) is a Python library for building reliable natural language interfaces. Here is how you can easily get started with it, and test its performance on the benchmark task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install marvin --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "\n",
    "@marvin.fn\n",
    "def process(\n",
    "    resume:str = resume,\n",
    "    question: str = question,\n",
    ") -> DataModel:\n",
    "    \"\"\"\n",
    "    Extract content from `resume`.\n",
    "    Answer the `question`, storing the result in cost, and the step-by-step reasoning in reasoning.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 16:29:20,717.717 INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'email': 'john.doe@gmail.com',\n",
       " 'cost': 2115.0,\n",
       " 'reasoning': 'John charges $50 for the first 29 hours of work and 1.7 times his base rate for any additional hours. This week, he worked 38 hours. \\n\\nStep-by-step reasoning: \\n1. Calculate the cost for the first 29 hours: \\n29 hours * $50/hour = $1450.\\n2. Calculate the additional hours worked: \\n38 hours - 29 hours = 9 hours.\\n3. Calculate the cost for the additional hours at 1.7 times the base rate: \\n9 hours * ($50/hour * 1.7) = 9 hours * $85/hour = $765.\\n4. Add the two amounts to get the total charge: \\n$1450 + $765 = $2215.',\n",
       " 'experience': ['Software Engineer Intern at Google from May 2022 to August 2022',\n",
       "  'Software Engineer Intern at Facebook from May 2021 to August 2021'],\n",
       " 'skills': ['Python', 'C++', 'Java']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marvin_response = process(resume, question)\n",
    "\n",
    "marvin_dict = marvin_response.model_dump()\n",
    "marvin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvin error: $100.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Marvin error: ${abs(marvin_dict[\"cost\"]-true_answer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BAML\n",
    "\n",
    "[BAML](https://www.boundaryml.com) is a domain specific language to write and test LLM functions developed by Boundary. Here is how you can easily get started with it, and test its performance on the benchmark task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: baml-py in /opt/miniconda3/envs/instill/lib/python3.11/site-packages (0.53.1)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/instill/bin/baml-cli\", line 8, in <module>\n",
      "    sys.exit(invoke_runtime_cli())\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "baml_py.BamlError: Destination directory already contains a baml_src directory: ./baml_src\n"
     ]
    }
   ],
   "source": [
    "!pip install baml-py\n",
    "!baml-cli init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Defining a data model.\n",
      "class Resume {\n",
      "  name string\n",
      "  email string\n",
      "  cost float\n",
      "  reasoning string\n",
      "  experience string[]\n",
      "  skills string[]\n",
      "}\n",
      "\n",
      "// Creating a function to extract the resume from a string.\n",
      "function ExtractResume(resume: string) -> Resume {\n",
      "  client GPT4\n",
      "  prompt #\"\n",
      "    Extract from this content:\n",
      "    {{ resume }}\n",
      "    Answer the question, storing the result in cost, and the step-by-step reasoning in reasoning.\n",
      "\n",
      "    {{ ctx.output_format }}\n",
      "  \"#\n",
      "}\n",
      "\n",
      "// Testing the function with a sample resume.\n",
      "test vaibhav_resume {\n",
      "  functions [ExtractResume]\n",
      "  args {\n",
      "    resume #\"\n",
      "      Vaibhav Gupta\n",
      "      vbv@boundaryml.com\n",
      "\n",
      "      Experience:\n",
      "      - Founder at BoundaryML\n",
      "      - CV Engineer at Google\n",
      "      - CV Engineer at Microsoft\n",
      "\n",
      "      Skills:\n",
      "      - Rust\n",
      "      - C++\n",
      "    \"#\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = 'baml_src/resume.baml'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    file_data = file.read()\n",
    "\n",
    "updated_file_data = file_data.replace(\n",
    "    '// Defining a data model.\\nclass Resume {\\n  name string\\n  email string\\n  experience string[]\\n  skills string[]\\n}',\n",
    "    '// Defining a data model.\\nclass Resume {\\n  name string\\n  email string\\n  cost float\\n  reasoning string\\n  experience string[]\\n  skills string[]\\n}'\n",
    "    ).replace(\n",
    "    'Extract from this content:\\n    {{ resume }}\\n\\n',\n",
    "    'Extract from this content:\\n    {{ resume }}\\n    Answer the question, storing the result in cost, and the step-by-step reasoning in reasoning.\\n\\n'\n",
    "    )\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(updated_file_data)\n",
    "\n",
    "print(updated_file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1 baml_client\n"
     ]
    }
   ],
   "source": [
    "!baml-cli generate\n",
    "from baml_client.sync_client import b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'email': 'john.doe@gmail.com',\n",
       " 'cost': 2100.0,\n",
       " 'reasoning': 'For the first 29 hours, John charges his base rate, totaling $50 * 29 = $1450. For the additional 9 hours, as he worked 38 hours, he charges 1.7 times his base rate, totaling $85 * 9 = $765. Adding these two amounts together, John charges his client $1450 + $765 = $2215 for the 38 hours this week.',\n",
       " 'experience': ['Software Engineer Intern at Google from May 2022 to August 2022 where he worked on the Google Search team, developed new features for the search engine, and wrote code in Python and C++.',\n",
       "  'Software Engineer Intern at Facebook from May 2021 to August 2021 where he worked on the Facebook Messenger team, developed new features for the messenger app, and wrote code in Python and Java.'],\n",
       " 'skills': ['Python', 'C++', 'Java']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baml_response = b.ExtractResume(context)\n",
    "\n",
    "baml_dict = baml_response.model_dump()\n",
    "baml_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAML error: $115.0\n"
     ]
    }
   ],
   "source": [
    "print(f'BAML error: ${abs(baml_dict[\"cost\"]-true_answer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TypeChat\n",
    "\n",
    "[TypeChat](https://microsoft.github.io/TypeChat/) is a tool from Microsoft for getting well-typed responses from language models. Here is how you can easily get started with it, and test its performance on the benchmark task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"typechat @ git+https://github.com/microsoft/TypeChat#subdirectory=python\" --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing_extensions import Annotated, Doc\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TypeChatDataModel:\n",
    "    name: Annotated[str, Doc(\"The name of the candidate\")]\n",
    "    email: Annotated[str, Doc(\"The email address of the candidate\")]\n",
    "    cost: Annotated[str, Doc(\"The cost of hiring the candidate for the project\")]\n",
    "    reasoning: Annotated[str, Doc(\"The reasoning provided by the cost calculation\")]\n",
    "    experience: Annotated[list[str], Doc(\"A list of experiences the candidate has\")]\n",
    "    skills: Annotated[list[str], Doc(\"A list of skills the candidate possesses\")]\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"email\": self.email,\n",
    "            \"cost\": self.cost,\n",
    "            \"reasoning\": self.reasoning,\n",
    "            \"experience\": self.experience,\n",
    "            \"skills\": self.skills,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typechat import TypeChatJsonTranslator, TypeChatValidator, create_language_model\n",
    "\n",
    "env_vars = {'OPENAI_API_KEY': os.getenv('OPENAI_API_KEY'), 'OPENAI_MODEL': 'gpt-3.5-turbo'}\n",
    "\n",
    "model = create_language_model(env_vars)\n",
    "validator = TypeChatValidator(TypeChatDataModel)\n",
    "translator = TypeChatJsonTranslator(model, validator, TypeChatDataModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 16:29:59,143.143 INFO     HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'John Doe',\n",
       " 'email': 'john.doe@gmail.com',\n",
       " 'cost': '$935',\n",
       " 'reasoning': 'Base rate for first 29 hours: $50/hour * 29 hours = $1450\\nAdditional hours: 9 hours * $50/hour * 1.7 = $765\\nTotal cost: $1450 + $765 = $2215\\nClient worked 38 hours, so cost for 38 hours: $50/hour * 29 hours + $50/hour * 1.7 * 9 hours = $935',\n",
       " 'experience': ['Software Engineer Intern at Google (May 2022 - August 2022)',\n",
       "  'Software Engineer Intern at Facebook (May 2021 - August 2021)'],\n",
       " 'skills': ['Python', 'C++', 'Java']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typechat_response = await translator.translate(prompt)\n",
    "\n",
    "typechat_dict = typechat_response.value.to_dict()\n",
    "typechat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeChat error: $1280.0\n"
     ]
    }
   ],
   "source": [
    "print(f'TypeChat error: ${abs(float(typechat_dict[\"cost\"][1:])-true_answer)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
