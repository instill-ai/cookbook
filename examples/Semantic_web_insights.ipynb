{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/instill-ai/cookbook/main/images/Logo.png\" alt=\"Instill Logo\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Web Insights\n",
    "\n",
    "In this notebook, we will leverage the **Crawl Website** feature of our [Web Operator](https://www.instill.tech/docs/component/operator/web) component to generate high-quality Markdown from a website. We will then use the **Chunk Text** feature of our [Text Operator](https://www.instill.tech/docs/component/operator/text) to break the generated Markdown into manageable pieces, followed by embedding those chunks using the **[Jina CLIP V1](https://instill.tech/instill-ai/models/jina-clip-v1/playground?version=v0.1.0)** model served via [Instill Model](https://www.instill.tech/docs/model/introduction). Finally, we will perform downstream analysis and visualization of the rich semantic information captured in the embeddings.\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "The ability to extract meaningful insights from web content is crucial for developing AI and ML applications. By converting web pages into structured Markdown format, we can maintain essential formatting while enabling AI models to process and understand the information efficiently. This structured approach allows for improved data handling, analysis, and semantic search capabilities.\n",
    "\n",
    "### Overview of the Process\n",
    "\n",
    "Our workflow consists of the following key steps:\n",
    "\n",
    "1. **Crawl a Website** using the [**website-to-markdown**](https://instill.tech/george_strong/pipelines/website-to-markdown/playground) pipeline to generate high-quality Markdown content.\n",
    "2. **Chunk the Markdown** using the [**chunk-markdown**](https://instill.tech/george_strong/pipelines/chunk-markdown/playground) pipeline, allowing for custom strategy to enhance manageability and semantic relevance.\n",
    "3. **Embed the Chunks** with Jina CLIP V1 to create semantic representations.\n",
    "4. **Perform Clustering and Visualization** to analyze the relationships and distributions of the embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "To execute all of the code in this notebook, you’ll need to create a free Instill Cloud account and setup an API Token. To create your account, please refer to our [quickstart guide](https://www.instill.tech/docs/quickstart). For generating your API Token, consult the [API Token Management](https://www.instill.tech/docs/core/token) page.\n",
    "\n",
    "**This will give you access to 10,000 free credits per month that you can use to make API calls with third-party AI vendors. Please see our [documentation](https://www.instill.tech/docs/cloud/credit) for further details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will now install the Instill Python SDK, import the required libraries, and configure the SDK with a valid API token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install instill-sdk==0.13.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from instill.clients import init_core_client\n",
    "core = init_core_client(api_token=os.environ['INSTILL_API_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **[Crawl Website](https://www.instill.tech/docs/component/operator/web#crawl-website)** to Generate High-quality Markdown\n",
    "\n",
    "We will start by crawling a specified website to extract the contents of each page and convert it into Markdown format. The following code triggers the [**website-to-markdown**](https://instill.tech/george_strong/pipelines/website-to-markdown/playground) pipeline and retrieves the Markdown representation of each page stored in a list.\n",
    "\n",
    "Feel free to change the `url`, and `max_pages` to customize how many pages on a site you wish to crawl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = core.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.instill.tech/\"\n",
    "max_pages = 8\n",
    "include_tags = [\"p\", \"h3\"]\n",
    "remove_tags = []\n",
    "\n",
    "response_crawler = pipeline.trigger(\n",
    "    namespace_id=\"george_strong\",\n",
    "    pipeline_id=\"website-to-markdown\",\n",
    "    data=[{\"max-k\": max_pages, \n",
    "           \"url\": url,\n",
    "           \"include-tags\": include_tags,\n",
    "           \"remove-tags\": remove_tags}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instill AI\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/hero/1.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/hero/3.svg)![beam](http://www.instill.tech/images/landing-page/hero/4.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/hero/2.svg)![beam](http://www.instill.tech/images/landing-page/hero/4.svg)![beam](http://www.instill.tech/images/landing-page/hero/8.svg)![beam](http://www.instill.tech/images/landing-page/hero/10.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/hero/9.svg)![beam](http://www.instill.tech/images/landing-page/hero/8.svg)![beam](http://www.instill.tech/images/landing-page/hero/10.svg)\n",
      "\n",
      "![blurred spot](http://www.instill.tech/images/landing-page/3.svg)![blurred spot](http://www.instill.tech/images/landing-page/4.svg)![beam](http://www.instill.tech/images/landing-page/1.svg)![beam](http://www.instill.tech/images/landing-page/2.svg)![blurred spot](http://www.instill.tech/images/landing-page/5.svg)![blurred spot](http://www.instill.tech/images/landing-page/6.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/7.svg)![beam](http://www.instill.tech/images/landing-page/8.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/9.svg)\n",
      "\n",
      "![beam](http://www.instill.tech/images/landing-page/10.svg)![beam](http://www.instill.tech/images/landing-page/12.svg)![beam](http://www.instill.tech/images/landing-page/11.svg)\n",
      "\n",
      "Hacktoberfest 2024! [Win Instill AI Swag Pack!](https://www.instill.tech/blog/hacktoberfest-2024-opening)\n",
      "\n",
      "ExploreFor BusinessFor DevelopersCompany [Pricing](http://www.instill.tech/pricing)\n",
      "\n",
      "Get Started\n",
      "\n",
      "Make Your Data\n",
      "\n",
      "AI-Ready\n",
      "\n",
      "Meet Instill Core, a source-available full-stack AI solution for tech teams—streamline your data operations and unlock the potential of unstructured data.All with one line of code.\n",
      "\n",
      "[Get Started](https://instill.tech/login) [GitHub](https://github.com/instill-ai/instill-core)\n",
      "\n",
      "Docker Compose\n",
      "\n",
      "Helm Chart\n",
      "\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "Status Quo\n",
      "\n",
      "Building a basic RAG pipeline is easy, but preprocessing unstructured data and always retrieving highly relevant results, takes effort.\n",
      "\n",
      "Complex Data Cleaning\n",
      "\n",
      "80% of enterprise data is unstructured in unusable format and difficult to clean.\n",
      "\n",
      "Broken or Rigid Data Flow\n",
      "\n",
      "Data flows for AI can be very complex, requiring rich integrations and and customized automation.\n",
      "\n",
      "Hallucinations in answers\n",
      "\n",
      "Stuck with LLMs that produce inaccurate, irrelevant or even fabricated answers.\n",
      "\n",
      "Struggling to Scale\n",
      "\n",
      "You're bogged down by infrastructure maintenance work that has little business impact.\n",
      "\n",
      "Expensive\n",
      "\n",
      "It's tough to control budgets and get quick results with complex AI systems.\n",
      "\n",
      "Fragmented Tools\n",
      "\n",
      "Your data, models, workflows and operations are fragmented across a galaxy of tools.\n",
      "\n",
      "Solution\n",
      "\n",
      "The World's First Full-stack AI solution\n",
      "\n",
      "Making your data RAG-ready out-of-the-box\n",
      "\n",
      "[GitHub](https://github.com/instill-ai/instill-core) [Discover Stack](http://www.instill.tech/docs/welcome)\n",
      "\n",
      "Make your data AI-ready\n",
      "\n",
      "Transform Unstructured Data into AI-Ready Augmented Data Catalog\n",
      "\n",
      "**Instill Catalog** easily converts documents, images, audio, and video into a unified format. It simplifies data cleaning, reduces errors, automates updates, and ensures your data is RAG-ready for AI applications. With built-in data lineage support, you can track data origins, transformations, and flows, ensuring transparency and maintaining data integrity.\n",
      "\n",
      "Text\n",
      "\n",
      "Image\n",
      "\n",
      "Audio\n",
      "\n",
      "Video\n",
      "\n",
      "PDF\n",
      "\n",
      "JSON\n",
      "\n",
      "CSV\n",
      "\n",
      "More\n",
      "\n",
      "![Data transform chart](http://www.instill.tech/images/landing-page/full-stack-solution/slides/desktop/1.svg)\n",
      "\n",
      "[How it works](http://www.instill.tech/docs/artifact/upload-files)\n",
      "\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "API-first & Developer-friendly\n",
      "\n",
      "Precise Retrieval Grounded in Your Data via Simple APIs\n",
      "\n",
      "Retrieve relevant results grounded in your data via simple APIs provided by Instill Catalog. Ideal for developers building intelligent search and Q&A services, such as AI assistants, with no deep technical expertise in LLM or RAG required.\n",
      "\n",
      "![Data transform chart](http://www.instill.tech/images/landing-page/full-stack-solution/slides/desktop/2.svg)\n",
      "\n",
      "[How it works](http://www.instill.tech/docs/artifact/search)\n",
      "\n",
      "```\n",
      "\n",
      "```\n",
      "\n",
      "Flexible switching of models across vendors\n",
      "\n",
      "Switch Models Across Vendors or Run Any Open-source Model to Save Costs\n",
      "\n",
      "Flexibly use state-of-the-art models across different vendors, or you can run any open-source AI models, automatically scale up and down, ensuring reliable compute resources without manual maintenance. Our high-performance platform serves your AI models with ease. **From Setup to Scaling, We've Got Infra Covered.**\n",
      "\n",
      "[How it works](http://www.instill.tech/docs/model/introduction)\n",
      "\n",
      "![Data transform chart](http://www.instill.tech/images/landing-page/full-stack-solution/slides/desktop/5.svg)\n",
      "\n",
      "Model Vendors\n",
      "\n",
      "![OpenAI logo](http://www.instill.tech/assets/openai.svg)OpenAI\n",
      "\n",
      "![Anthropic logo](http://www.instill.tech/assets/anthropic.svg)Anthropic\n",
      "\n",
      "![Cohere logo](http://www.instill.tech/assets/cohere.svg)Cohere\n",
      "\n",
      "![Mistral AI logo](http://www.instill.tech/assets/mistral-ai.svg)Mistral AI\n",
      "\n",
      "![Hugging Face logo](http://www.instill.tech/assets/hugging-face.svg)Hugging\n",
      "\n",
      "Face\n",
      "\n",
      "More\n",
      "\n",
      "Instill Model\n",
      "\n",
      "🌋LLaVa\n",
      "\n",
      "![Meta logo](http://www.instill.tech/assets/meta.svg)Llama 3\n",
      "\n",
      "![Meta logo](http://www.instill.tech/assets/meta.svg)Llamacode\n",
      "\n",
      "More\n",
      "\n",
      "Unstructured data ETL\n",
      "\n",
      "Orchestrate pipelines to pre-process and transform data to keep it relevant\n",
      "\n",
      "Fix broken data flows and improve data quality to your AI applications. Create DAGs of dependencies, connect third-party data sources, AI models, operations, and applications. Automate ETL processes to manage and orchestrate the entire pipeline in a single interface, powering your applications and business efficiently.\n",
      "\n",
      "![GCS](http://www.instill.tech/assets/gcs.svg)GCS\n",
      "\n",
      "![BigQuery](http://www.instill.tech/assets/bigquery.svg)BigQuery\n",
      "\n",
      "![Gmail](http://www.instill.tech/assets/gmail.svg)Gmail\n",
      "\n",
      "![HubSpot](http://www.instill.tech/assets/hubspot.svg)HubSpot\n",
      "\n",
      "![Slack logo](http://www.instill.tech/assets/slack.svg)Slack\n",
      "\n",
      "[See integrations](http://www.instill.tech/integrations)\n",
      "\n",
      "![Data transform chart](http://www.instill.tech/images/landing-page/full-stack-solution/slides/desktop/3.svg)\n",
      "\n",
      "One Platform. Run Anywhere. Zero Hassle.\n",
      "\n",
      "Forget about gluing different tools together. Our platform integrates seamlessly with your systems, making scaling your AI applications effortless. It streamlines data handling, enhances AI accuracy, continuously optimizes through monitoring, and effectively manages infrastructure. This allows you to expand your AI applications efficiently and cost-effectively. Enjoy native compatibility at every stage for hassle-free maintenance.\n",
      "\n",
      "[How it works](http://www.instill.tech/docs/core/introduction)\n",
      "\n",
      "![Data transform stages](http://www.instill.tech/images/landing-page/full-stack-solution/slides/desktop/4.svg)![Data transform stages](http://www.instill.tech/images/landing-page/full-stack-solution/slides/mobile/4.svg)\n",
      "\n",
      "Secure and Enterprise-ready\n",
      "\n",
      "Meet Security and Operational Requirements to Ship AI Faster\n",
      "\n",
      "Cloud-native\n",
      "\n",
      "Fully managed on your choice of public cloud, Bring Your Own Cloud (BYOC), or on-premises.\n",
      "\n",
      "![Instill Cloud logo](http://www.instill.tech/assets/instill-cloud.svg)Instill Cloud\n",
      "\n",
      "![Google Cloud logo](http://www.instill.tech/assets/google-cloud.svg)Google Cloud\n",
      "\n",
      "![Amazon Web Services logo](http://www.instill.tech/assets/aws.svg)Amazon Web Services\n",
      "\n",
      "![Microsoft Azure logo](http://www.instill.tech/assets/azure.svg)Microsoft Azure\n",
      "\n",
      "On Premises\n",
      "\n",
      "Security & Privacy\n",
      "\n",
      "Control your data securely with TLS encryption and strict retention policies.\n",
      "\n",
      "![SOC 2 logo](http://www.instill.tech/assets/aicpa-soc.png)SOC 2\n",
      "\n",
      "![GDPR logo](http://www.instill.tech/assets/gdpr.png)GDPR\n",
      "\n",
      "Want results like these?\n",
      "\n",
      "[Book a Demo](https://cal.com/patrick-sheridan-5oacrl/30min)\n",
      "\n",
      "10X\n",
      "\n",
      "Faster to develop and ship your AI applications\n",
      "\n",
      "30%\n",
      "\n",
      "Capacity boost to break down data and AI team silos\n",
      "\n",
      "$2M\n",
      "\n",
      "Saved on R&D budget for more efficient resource use\n",
      "\n",
      "Use Cases\n",
      "\n",
      "TransformingUse CasesAcross Sectors\n",
      "\n",
      "Find out how your business can benefit from AI\n",
      "\n",
      "Customer Support\n",
      "\n",
      "AI Assistant for Customer Support\n",
      "\n",
      "AI Customer Assistant provides 24/7 support, automates inquiries, and personalizes recommendations.\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Workflow Automation\n",
      "\n",
      "AI Document Analysis Assistant\n",
      "\n",
      "Upload any Document and engage in AI-powered conversations.\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Agriculture\n",
      "\n",
      "Agricultural Biotechnology AI Image Analyzer\n",
      "\n",
      "Automatically detect, classify, and analyze visual data with high precision and efficiency.\n",
      "\n",
      "Computer Vision\n",
      "\n",
      "Workflow Automation\n",
      "\n",
      "Healthcare\n",
      "\n",
      "AI Infection Diagnosis Assistant\n",
      "\n",
      "Automate data extraction, analysis, and interpretation for medical diagnosis.\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Insurance\n",
      "\n",
      "Insurance Due Diligence Assistant\n",
      "\n",
      "Automate due diligence with real-time data aggregation and AI-powered analysis for risk evaluation.\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Workflow Automation\n",
      "\n",
      "Finance\n",
      "\n",
      "AI Market Analysis Assistant\n",
      "\n",
      "Predictive Market Intelligence to extract trends, generate insights, and receive tailored market strategies.\n",
      "\n",
      "AI Assistant\n",
      "\n",
      "Workflow Automation\n",
      "\n",
      "[Explore More](http://www.instill.tech/use-cases)\n",
      "\n",
      "![blurred spot](http://www.instill.tech/images/bottom-cta/3.svg)![beam](http://www.instill.tech/images/bottom-cta/2.svg)\n",
      "\n",
      "![line](http://www.instill.tech/images/bottom-cta/1.svg)\n",
      "\n",
      "AI infrastructure for Enterprise\n",
      "\n",
      "[Get Started](https://instill.tech/login) [Book a Demo](https://cal.com/patrick-sheridan-5oacrl/30min)\n"
     ]
    }
   ],
   "source": [
    "md_pages = MessageToDict(response_crawler)['outputs'][0]['crawled-content']\n",
    "\n",
    "print(md_pages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Markdown\n",
    "\n",
    "After generating the Markdown content for each page, we will chunk it using the **Chunk Text** feature of our [Text Operator](https://www.instill.tech/docs/component/operator/text). This step is crucial for breaking down the content into smaller, more manageable segments, which will facilitate better embeddings and downstream analysis.\n",
    "\n",
    "The following code loops over the Markdown formatted content, and triggers the [**chunk-markdown**](https://instill.tech/george_strong/pipelines/chunk-markdown/playground) pipeline for each page, populating `chunked_pages`. This is simply a list of lists, containing a list of text chunks for each page.\n",
    "\n",
    "Feel free to try out different chunking strategies (\"Markdown\", \"Recursive\" or \"Token\"), edit the `max_chunk_length` or `chunk_overlap` to customize the chunking behavior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = \"Markdown\"\n",
    "max_chunk_length = 1200\n",
    "chunk_overlap = 10\n",
    "\n",
    "chunked_pages = []\n",
    "\n",
    "for web_page in md_pages:\n",
    "    response = pipeline.trigger(\n",
    "        namespace_id=\"george_strong\",\n",
    "        pipeline_id=\"chunk-markdown\",\n",
    "        data=[{\"md-input\": web_page,\n",
    "               \"chunk-strategy\": strategy,\n",
    "               \"max-chunk-length\": max_chunk_length,\n",
    "               \"chunk-overlap\": chunk_overlap}]\n",
    "    )\n",
    "    response = MessageToDict(response)\n",
    "    chunks = [item['text'] for item in response['outputs'][0]['response']]\n",
    "    chunked_pages.append(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Chunks\n",
    "\n",
    "Now that we have our chunks, we will use the **[Jina CLIP V1](https://instill.tech/instill-ai/models/jina-clip-v1/playground?version=v0.1.0)** embedding model to generate semantic representations for each chunk. This step will allow us to analyze the meaning and context of the content captured in the Markdown.\n",
    "\n",
    "First we will initialize an Instill Model client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = core.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define a function that takes a list of chunks, e.g. the chunks for a single web page, and generates a corresponding list of embedding vectors using **[Jina CLIP V1](https://instill.tech/instill-ai/models/jina-clip-v1/playground?version=v0.1.0)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks(text_chunks):\n",
    "\n",
    "    # create the input payload\n",
    "    embeddings = [{\"text\": text, \"type\": \"text\"} for text in text_chunks]\n",
    "\n",
    "    input = {\n",
    "        \"data\": {\n",
    "            \"embeddings\": embeddings\n",
    "        },\n",
    "        \"parameter\": {\n",
    "            \"format\": \"float\",\n",
    "        }, \n",
    "    }\n",
    "\n",
    "    # trigger the model\n",
    "    response = model.trigger(\n",
    "        namespace_id=\"instill-ai\",\n",
    "        model_id=\"jina-clip-v1\",\n",
    "        version=\"v0.1.0\",\n",
    "        task_inputs=[input],\n",
    "    )\n",
    "\n",
    "    # extract and return the embedding vectors\n",
    "    response = MessageToDict(response)\n",
    "    vectors = [embedding['vector'] for embedding in response['taskOutputs'][0]['data']['embeddings']]\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now loop over the pages, embedding all the chunks on each page batch-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_pages = []\n",
    "\n",
    "for page in chunked_pages:\n",
    "    embedded_pages.append(embed_chunks(page))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and Visualization\n",
    "\n",
    "To gain insights into the relationships between the embedded chunks, we will perform clustering and visualization. This will help us understand the distribution and semantic structure of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn --quiet\n",
    "!pip install bokeh --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "from bokeh.palettes import Category10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP Dimensionality Reduction\n",
    "\n",
    "First, we will apply UMAP for dimensionality reduction to visualize the high-dimensional embeddings in a 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_embeddings = [vector for page in embedded_pages for vector in page]\n",
    "flattened_chunks = [chunk for chunks in chunked_pages for chunk in chunks]\n",
    "\n",
    "X = np.array(flattened_embeddings)\n",
    "\n",
    "umap_model = umap.UMAP(n_components=2, n_neighbors=40, random_state=42)\n",
    "reduced_embeddings = umap_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering\n",
    "\n",
    "Next, we will use K-Means clustering to identify semantically related groups within the reduced embeddings, which can reveal interesting patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 6\n",
    "\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(reduced_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive Plot using Bokeh\n",
    "\n",
    "Finally, we will create an interactive plot using Bokeh to visualize the clusters and the corresponding chunks of text. This will provide an intuitive and interactive way of exploring and understanding the semantic structure contained in the website!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(data=dict(\n",
    "    x=reduced_embeddings[:, 0],\n",
    "    y=reduced_embeddings[:, 1],\n",
    "    text=flattened_chunks,\n",
    "    cluster=cluster_labels\n",
    "))\n",
    "\n",
    "colors = Category10[num_clusters]\n",
    "source.data['color'] = [colors[label] for label in cluster_labels]\n",
    "\n",
    "plot = figure(title='Visualize Crawled Website Embeddings',\n",
    "              tools=\"pan,wheel_zoom,box_zoom,reset\",\n",
    "              x_axis_label='UMAP 1',\n",
    "              y_axis_label='UMAP 2',\n",
    "              width=900,\n",
    "              height=600)\n",
    "\n",
    "plot.scatter('x', 'y', source=source, size=8, color='color', alpha=0.6)\n",
    "\n",
    "hover_tool = HoverTool()\n",
    "hover_tool.tooltips = \"\"\"\n",
    "    <div style=\"width: 400px; white-space: normal;\">\n",
    "        <div><strong>Text Chunk:</strong></div>\n",
    "        <div>@text</div>\n",
    "    </div>\n",
    "\"\"\"\n",
    "\n",
    "plot.add_tools(hover_tool)\n",
    "\n",
    "output_notebook()\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.close()\n",
    "model.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
